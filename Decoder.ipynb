{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa45321-91bd-4ef4-91cb-d7219e9c16f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from EncoderTransformer.ipynb\n",
      "tf.Tensor(\n",
      "[[[ 0.5888975  -0.03546252  1.2934693  ...  0.29983702 -0.12287652\n",
      "    1.1293975 ]\n",
      "  [-0.33865193  0.5251558   0.98935276 ...  0.5499459  -0.5448272\n",
      "    0.9404903 ]\n",
      "  [ 0.96026725 -0.0517008   0.673421   ...  0.51295304 -0.5779533\n",
      "    1.6848341 ]\n",
      "  [ 0.10532728  0.25390226  1.3362669  ...  0.4487259  -0.67684835\n",
      "    1.2439642 ]\n",
      "  [ 0.28498533  0.07896406  1.1497618  ... -0.5809479  -1.048168\n",
      "    0.06464329]]\n",
      "\n",
      " [[ 0.49799728  0.24435085  1.6806055  ...  1.3838269   0.3301044\n",
      "    0.8125566 ]\n",
      "  [ 0.6332804   0.00798275  1.9614557  ...  1.4987017  -0.27502206\n",
      "    1.915403  ]\n",
      "  [ 1.5618489   1.0401852   1.0593464  ...  1.318754    1.032027\n",
      "    1.4514806 ]\n",
      "  [-0.1379486  -0.147596    2.0032861  ...  1.5441874  -0.32821053\n",
      "    1.0109472 ]\n",
      "  [ 0.53216666  0.6764732   1.3017755  ...  0.7820213  -0.66310406\n",
      "   -0.00645708]]\n",
      "\n",
      " [[ 0.00663272  0.08982807  1.0020491  ...  1.9915534  -0.82418656\n",
      "    0.46473923]\n",
      "  [-0.12742728  0.84888506  0.77184576 ...  0.71358407 -0.39220148\n",
      "    0.20405114]\n",
      "  [ 0.86936885  0.07995664  0.20487362 ...  1.1989473  -0.82815325\n",
      "    0.56492406]\n",
      "  [ 0.2295566  -0.16098851  1.4589303  ...  1.0759305  -0.6666997\n",
      "   -0.581262  ]\n",
      "  [-0.29324284  0.05783622  0.8493548  ...  0.8108824  -0.342259\n",
      "   -0.09406549]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.8948704   0.24299957  0.9827534  ...  0.27208143 -0.67076415\n",
      "    0.7335963 ]\n",
      "  [ 0.0971396   0.78222746  0.5150096  ...  0.97738034 -0.7522124\n",
      "    1.5581081 ]\n",
      "  [ 1.7748102   0.71800375  0.06983887 ...  1.3644166  -0.4224673\n",
      "    0.0839231 ]\n",
      "  [ 0.48200572 -0.2121278   1.6729037  ...  1.2393446  -0.7805993\n",
      "    0.96892136]\n",
      "  [ 0.22833231 -0.24280763  0.63241655 ...  0.7124029  -1.0873333\n",
      "    0.43788946]]\n",
      "\n",
      " [[-0.15301816  0.88516885  1.583382   ...  0.93243617 -0.7705734\n",
      "    1.9655322 ]\n",
      "  [ 0.13800262  0.41067374  1.8645904  ...  0.01536956 -0.5538418\n",
      "    1.4850489 ]\n",
      "  [ 0.27476555  0.27879292  1.6895168  ...  0.24571383 -0.72346276\n",
      "    1.2339693 ]\n",
      "  [ 0.61399394  0.18125965  2.4688363  ...  0.97979635 -1.2160206\n",
      "    1.2667072 ]\n",
      "  [-0.5315911  -0.10441983  2.1360767  ...  0.6955956  -0.8229537\n",
      "    0.77717817]]\n",
      "\n",
      " [[ 0.297544    0.01176446  0.73958755 ...  0.41773757 -0.8968526\n",
      "    0.8075059 ]\n",
      "  [-0.08307676  0.18370397  1.7117457  ...  0.80361813 -0.3787002\n",
      "    1.1874772 ]\n",
      "  [ 0.61542463  0.98618734  1.1601988  ...  0.9605221  -0.43761668\n",
      "    0.14257997]\n",
      "  [ 0.2913323  -0.25605187  1.9287252  ...  1.1002555  -0.94745344\n",
      "    1.1873442 ]\n",
      "  [ 0.22379348 -0.52344376  1.2568102  ...  0.85799783 -0.4435111\n",
      "    0.7682798 ]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from EncoderTransformer import AddNormalization,FeedForward,PositionEmbeddingFixedWeights,MultiHeadAttention\n",
    "from tensorflow.keras.layers import Dropout,Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c784fe7f-d680-43a6-a0af-114f485b69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(Layer):\n",
    "    def __init__(self,h,d_k,d_v,d_model,d_ff,rate,**kwargs):\n",
    "        super(DecoderLayer,self).__init__(**kwargs)\n",
    "        self.multihead_attention1=MultiHeadAttention(h,d_k,d_v,d_model)\n",
    "        self.dropout1=Dropout(rate)\n",
    "        self.add_norm1=AddNormalization()\n",
    "        self.multihead_attention2=MultiHeadAttention(h,d_k,d_v,d_model)\n",
    "        self.dropout2=Dropout(rate)\n",
    "        self.add_norm2=AddNormalization()\n",
    "        self.feed_forward=FeedForward(d_ff,d_model)\n",
    "        self.dropout3=Dropout(rate)\n",
    "        self.add_norm3=AddNormalization()\n",
    "    \n",
    "    def call(self,x,encoder_output,lookahead_mask,padding_mask,training):\n",
    "        #multihead attention layer\n",
    "        multihead_output1=self.multihead_attention1(queries=x,keys=x,values=x,mask=lookahead_mask)\n",
    "        #expected shape: (batch_size,sequence_len,d_model)\n",
    "        \n",
    "        #dropout layer\n",
    "        multihead_output1=self.dropout1(multihead_output1,training=training)\n",
    "        \n",
    "        #normalization layer\n",
    "        addnorm_output1=self.add_norm1(x,multihead_output1)\n",
    "        #expected shape: (batch_size,seq_len,d_model)\n",
    "        \n",
    "        #multihead attention layer\n",
    "        multihead_output2=self.multihead_attention2(queries=addnorm_output1,keys=encoder_output,values=encoder_output,mask=padding_mask)\n",
    "        \n",
    "        #dropout layer\n",
    "        multihead_output2=self.dropout2(multihead_output2,training=training)\n",
    "        \n",
    "        #normalization\n",
    "        addnorm_output2=self.add_norm2(addnorm_output1,multihead_output2)\n",
    "        \n",
    "        #fully connected layer\n",
    "        feedforward_output=self.feed_forward(addnorm_output2)\n",
    "        #expected shape: (batch_size,seq_len,d_model)\n",
    "        \n",
    "        #normalization\n",
    "        return self.add_norm3(addnorm_output2,feedforward_output)\n",
    "    \n",
    "\n",
    "#implementing decoder\n",
    "\n",
    "class Decoder(Layer):\n",
    "    def __init__(self,vocab_size,sequence_length,h,d_k,d_v,d_model,d_ff,n,rate,**kwargs):\n",
    "        super(Decoder,self).__init__(**kwargs)\n",
    "        self.pos_encoding=PositionEmbeddingFixedWeights(sequence_length,vocab_size,d_model)\n",
    "        self.dropout=Dropout(rate)\n",
    "        self.decoder_layer=[DecoderLayer(h,d_k,d_v,d_model,d_ff,rate) for _ in range(n)]\n",
    "        \n",
    "    def call(self,output_target,encoder_output,lookahead_mask,padding_mask,training):\n",
    "        #generate pos encoding\n",
    "        pos_encoding_output=self.pos_encoding(output_target)\n",
    "        #output shape: (number of sentences,seq_len,d_model)\n",
    "        \n",
    "        #dropout layer\n",
    "        x=self.dropout(pos_encoding_output,training=training)\n",
    "        \n",
    "        #passing positional encoded values to each encoder layer\n",
    "        for i,layer in enumerate(self.decoder_layer):\n",
    "            x=layer(x=x,encoder_output=encoder_output,lookahead_mask=lookahead_mask,padding_mask=padding_mask,training=training)\n",
    "            # x,encoder_output,lookahead_mask,padding_mask,training\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4f9662-cb6b-4f22-aed2-d836f1c0b1a9",
   "metadata": {},
   "source": [
    "### testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319b7598-a5f6-4f62-a210-de1170453626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    " \n",
    "#same values as in the paper\n",
    "\n",
    "dec_vocab_size = 20  # Vocabulary size for the decoder\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "d_model = 512  # Dimensionality of the model sub-layers' outputs\n",
    "n = 6  # Number of layers in the decoder stack\n",
    " \n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584a2821-2939-44ef-8965-515766f8ebbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.81869984  0.07329611 -0.7121857  ...  0.06149567 -1.5820209\n",
      "   -0.9657264 ]\n",
      "  [ 0.42286608 -0.49725017 -0.6564052  ... -1.3056955  -1.1364115\n",
      "   -1.321313  ]\n",
      "  [ 0.6034274   0.9116654  -1.2240113  ... -0.69463056 -1.0881586\n",
      "   -1.1272588 ]\n",
      "  [ 0.70999557 -0.0203667  -0.37315777 ... -1.2273759  -0.68237084\n",
      "   -0.9260234 ]\n",
      "  [ 0.06351195  0.1670516  -0.34705114 ... -0.4679266  -1.1768199\n",
      "   -1.0989532 ]]\n",
      "\n",
      " [[ 0.6111519   0.5872731  -0.9024712  ... -0.6064365  -1.3971554\n",
      "   -0.42652026]\n",
      "  [ 0.3366668   0.06065558 -0.47282937 ... -0.94821805 -0.4994914\n",
      "   -0.97895104]\n",
      "  [ 0.56306094  0.61369336 -0.8127428  ... -0.6496656  -1.0926722\n",
      "   -0.6118529 ]\n",
      "  [ 0.818286    0.58568794 -0.15268405 ... -1.1520269  -1.4175295\n",
      "   -0.61413664]\n",
      "  [ 0.4942264   1.0535638  -0.09177745 ... -0.5824398  -1.1441345\n",
      "   -1.1041598 ]]\n",
      "\n",
      " [[ 0.28710374 -0.3347942  -0.6578675  ... -0.9090593  -1.2015926\n",
      "   -0.38640565]\n",
      "  [ 0.38105392  0.47729585  0.44782373 ... -1.1570584  -1.3183422\n",
      "   -0.82421714]\n",
      "  [ 0.06264284  0.7267973  -0.93024206 ... -0.46956524 -0.611873\n",
      "   -0.87459415]\n",
      "  [ 0.31978002  0.7841062  -0.8488498  ... -0.5411455  -1.3228637\n",
      "   -0.5638136 ]\n",
      "  [ 0.15103583  1.1968558  -0.61058366 ... -0.672293   -1.0949576\n",
      "   -0.51247287]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.4722188   0.0152348  -0.6859821  ... -0.5409469  -1.3551542\n",
      "   -0.48462483]\n",
      "  [ 0.41904178  0.4890494  -0.7977173  ... -1.0011208  -1.7478335\n",
      "   -1.1792828 ]\n",
      "  [ 0.73319834  0.3650675  -0.24415812 ... -0.9888825  -0.94504267\n",
      "   -1.2798785 ]\n",
      "  [ 0.17948742  0.7703797  -0.48175606 ... -0.8716302  -0.386575\n",
      "   -0.6257788 ]\n",
      "  [ 0.46299842  0.46685755 -0.394149   ...  0.12181704 -1.353044\n",
      "   -1.2724701 ]]\n",
      "\n",
      " [[ 0.74870026  0.6426153  -0.1750951  ... -0.61231893 -1.5759155\n",
      "   -0.9505575 ]\n",
      "  [ 0.39348313  0.35984093 -0.47705317 ... -1.3455935  -1.1204607\n",
      "   -1.4575305 ]\n",
      "  [ 0.06766692  0.12854335 -0.8070703  ... -0.80597657 -1.2811533\n",
      "   -1.2632177 ]\n",
      "  [ 0.3504201   0.37491983 -0.31052724 ... -1.0856972  -0.7590178\n",
      "   -0.7004545 ]\n",
      "  [ 0.37636498  0.8157009  -0.3635346  ... -0.5695048  -0.9318436\n",
      "   -1.362786  ]]\n",
      "\n",
      " [[ 0.98717237  0.15997328 -0.16083796 ... -1.0870464  -1.394956\n",
      "   -0.93361235]\n",
      "  [ 0.5206868   0.1340018   0.13833073 ... -1.5219586  -0.62348634\n",
      "   -0.8583602 ]\n",
      "  [ 0.81845725  0.58716273 -0.10665187 ... -1.1412008  -1.8139656\n",
      "   -1.1858808 ]\n",
      "  [ 0.7010582   0.25211507 -0.05693759 ... -1.2154212  -1.3115637\n",
      "   -0.7324275 ]\n",
      "  [ 0.7832687   0.5060395  -0.6919076  ...  0.05117926 -1.6234442\n",
      "   -0.32707012]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_seq = random.random((batch_size, input_seq_length))\n",
    "enc_output = random.random((batch_size, input_seq_length, d_model))\n",
    " \n",
    "decoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "print(decoder(output_target=input_seq, encoder_output=enc_output,lookahead_mask= None,padding_mask=None  ,training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5052cf2-b0a3-461d-90fd-70effdaacbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
