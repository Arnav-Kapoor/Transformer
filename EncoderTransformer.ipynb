{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f904ec7-cec3-4c91-a946-7b78005647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor, string\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, Layer,LayerNormalization,Dense,ReLU,Dropout\n",
    "import numpy as np\n",
    "from tensorflow import matmul,cast,float32,math,reshape,shape,transpose\n",
    "from tensorflow.keras.backend import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e75f2cf-aeb0-4edf-8a71-b8ddad200efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbeddingFixedWeights(Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, output_dim, **kwargs):\n",
    "        super(PositionEmbeddingFixedWeights, self).__init__(**kwargs)\n",
    "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)   \n",
    "        position_embedding_matrix = self.get_position_encoding(sequence_length, output_dim)                                          \n",
    "        self.word_embedding_layer = Embedding(\n",
    "            input_dim=vocab_size, output_dim=output_dim,\n",
    "            weights=[word_embedding_matrix],\n",
    "            trainable=False\n",
    "        )\n",
    "        self.position_embedding_layer = Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim,\n",
    "            weights=[position_embedding_matrix],\n",
    "            trainable=False\n",
    "        )\n",
    "             \n",
    "    def get_position_encoding(self, seq_len, d, n=10000):\n",
    "        P = np.zeros((seq_len, d))\n",
    "        for k in range(seq_len):\n",
    "            for i in np.arange(int(d/2)):\n",
    "                denominator = np.power(n, 2*i/d)\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return P\n",
    " \n",
    " \n",
    "    def call(self, inputs):        \n",
    "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636bfc4e-fe1b-467c-af0a-ca9a67e70672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNormalization(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(AddNormalization,self).__init__(**kwargs)\n",
    "        self.layer_norm=LayerNormalization()\n",
    "    \n",
    "    def call(self,x,sublayer_x):\n",
    "        #sublayer i/p and o/p need to be of the same shape to be summed\n",
    "        add=x+sublayer_x\n",
    "        \n",
    "        #apply layer normalization to the sum\n",
    "        return self.layer_norm(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250f9041-79ca-4e06-983b-808260f8315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(Layer):\n",
    "    def __init__(self,d_ff,d_model,**kwargs):\n",
    "        super(FeedForward,self).__init__(**kwargs)\n",
    "        self.fully_connected1=Dense(d_ff) #first fully connected layer\n",
    "        self.fully_connected2=Dense(d_model) #second fully connected layer\n",
    "        self.activation=ReLU() #relu activation layer\n",
    "    \n",
    "    def call(self,x):\n",
    "        #the i/p passed into the 2 fully connected layers,with a relu in b/w\n",
    "        x_fc1=self.fully_connected1(x)\n",
    "        \n",
    "        return self.fully_connected2(self.activation(x_fc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "331d5d27-08e3-4fd0-a13e-90a43ce02557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(DotProductAttention,self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self,queries,keys,values,d_k,mask=None):\n",
    "        scores=matmul(queries,keys,transpose_b=True)/math.sqrt(cast(d_k,float32))\n",
    "    \n",
    "    #applying mask so as to not base the occurence of a word on the basis of the words ahead\n",
    "        if mask is not None:\n",
    "            scores+= -1e9*mask\n",
    "        weights=softmax(scores)\n",
    "        \n",
    "        return matmul(weights,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26bc134f-8678-49bd-9f9a-3b151de24c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self,h,d_k,d_v,d_model,**kwargs):\n",
    "        super(MultiHeadAttention,self).__init__(**kwargs)\n",
    "        self.attention=DotProductAttention() #scaled dot product attention\n",
    "        self.heads=h #number of attention heads to use\n",
    "        self.d_k=d_k #dimentionality of linearly projected queries and keys\n",
    "        self.d_v=d_v #dimantionality of linearly projected values\n",
    "        self.d_model=d_model #dimentionality of the model\n",
    "        self.W_q=Dense(d_k) #learned projection matrix for the queries\n",
    "        self.W_k=Dense(d_k) #learned projection matrix for the keys\n",
    "        self.W_v=Dense(d_v) #learned projection matrix for the values\n",
    "        self.W_o=Dense(d_model) #leanred projection matrix for the multi head o/p\n",
    "        \n",
    "    def reshape_tensor(self,x,heads,flag):\n",
    "        if flag:\n",
    "            #tensor shape after reshaping and transposing: (batch_size,heads,seq_length,-1)\n",
    "            x=reshape(x,shape=(shape(x)[0],shape(x)[1],heads,-1))\n",
    "            x=transpose(x,perm=(0,2,1,3))\n",
    "        else:\n",
    "            #reverting the reshaping and transposing opertaions:(batch_size,seq,length,d_k)\n",
    "            x=transpose(x,perm=(0,2,1,3))\n",
    "            x=reshape(x,shape=(shape(x)[0],shape(x)[1],self.d_k))\n",
    "        return x\n",
    "    \n",
    "    def call(self,queries,keys,values,mask=None):\n",
    "        #rearrange the queries to be able to compute all heads in parallel\n",
    "        q_reshaped=self.reshape_tensor(self.W_q(queries),self.heads,True)\n",
    "        #resulting tensor shape: (batch_size,heads,input_seq_len,-1)\n",
    "        \n",
    "        #rearrange the keys to be able to compute all heads in parallel\n",
    "        k_reshaped=self.reshape_tensor(self.W_k(keys),self.heads,True)\n",
    "        \n",
    "        #rearrange the values to be able to compute all heads in parallel\n",
    "        v_reshaped=self.reshape_tensor(self.W_v(values),self.heads,True)\n",
    "        \n",
    "        #compute the multi head attention o/p using the reshaped q,k,v\n",
    "        o_reshaped=self.attention(q_reshaped,k_reshaped,v_reshaped,self.d_k,mask)\n",
    "        #resulting tensor shape: (batch_size,input_seq_len,-1)\n",
    "        \n",
    "        #rearrange back the o/p into concatenated form\n",
    "        output=self.reshape_tensor(o_reshaped,self.heads,False)\n",
    "        #resulting tensor shape: (batch_size,heads,input_seq_len,d_k)\n",
    "        \n",
    "        #apply one final layer linear projection to the o/p to generate the mutlihead attention\n",
    "        #resulting tensor shaoe:(batch_size,input_seq_len,d_model)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e74d2c-34bd-471b-8bb7-fc77b8141298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __init__(self,h,d_k,d_v,d_model,d_ff,rate,**kwargs):\n",
    "        super(EncoderLayer,self).__init__(**kwargs)\n",
    "        self.multihead_attention=MultiHeadAttention(h,d_k,d_v,d_model)\n",
    "        self.dropout1=Dropout(rate)\n",
    "        self.add_norm1=AddNormalization()\n",
    "        self.feed_forward=FeedForward(d_ff,d_model)\n",
    "        self.dropout2=Dropout(rate)\n",
    "        self.add_norm2=AddNormalization()\n",
    "        \n",
    "    def call(self,x,padding_mask,training):\n",
    "        #multihead attention layer\n",
    "        multihead_output=self.multihead_attention(x,x,x,padding_mask)\n",
    "        #expected o/p shape =(batch_size,seq_len,d_model)\n",
    "        \n",
    "        #dropout\n",
    "        multihead_output=self.dropout1(multihead_output,training=training)\n",
    "        \n",
    "        #Add and Norm Layer\n",
    "        addnorm_output=self.add_norm1(x,multihead_output)\n",
    "        #expected o/p shape=(batch_size,seq_len,d_model)\n",
    "        \n",
    "        #fully connected layer\n",
    "        feedforward_output=self.feed_forward(addnorm_output)\n",
    "        #expected shape=(batch_size,seq_len,d_model)\n",
    "        \n",
    "        #dropout layer\n",
    "        feedforward_output=self.dropout2(feedforward_output,training=training)\n",
    "        \n",
    "        #Add and Norm layer\n",
    "        return self.add_norm2(addnorm_output,feedforward_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcfd71b2-1e56-42bd-954c-ab983a52c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self,vocab_size,seq_len,h,d_k,d_v,d_model,d_ff,n,rate,**kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.pos_encoding=PositionEmbeddingFixedWeights(seq_len,vocab_size,d_model)\n",
    "        self.dropout=Dropout(rate)\n",
    "        self.encoder_layer=[EncoderLayer(h,d_k,d_v,d_model,d_ff,rate) for _ in range(n)]\n",
    "    \n",
    "    def call(self,input_seq,padding_mask,training):\n",
    "        #generate positional encoding\n",
    "        pos_encoding_output=self.pos_encoding(input_seq)\n",
    "        #expected output shape=(batch_size,seq_len,d_model)\n",
    "        \n",
    "        #droupout layer\n",
    "        x=self.dropout(pos_encoding_output,training=training)\n",
    "        \n",
    "        #passing positional encoded values to each encoder layer\n",
    "        for i ,layer in enumerate(self.encoder_layer):\n",
    "            x+layer(x,padding_mask,training)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbdd596-2c16-4db4-a841-11ae606eb0d3",
   "metadata": {},
   "source": [
    "### testing using dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec76bc70-3fa5-443e-97ef-ac2d62069178",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
      "    0.00000000e+00  2.22222233e+00]\n",
      "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
      "    1.15181436e-04  2.22222233e+00]\n",
      "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
      "    2.30362872e-04  2.22222233e+00]\n",
      "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
      "    3.45544337e-04  2.22222233e+00]\n",
      "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
      "    0.00000000e+00  2.22222233e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
      "    0.00000000e+00  2.22222233e+00]\n",
      "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
      "    1.15181436e-04  0.00000000e+00]\n",
      "  [ 0.00000000e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
      "    2.30362872e-04  2.22222233e+00]\n",
      "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
      "    3.45544337e-04  2.22222233e+00]\n",
      "  [ 0.00000000e+00  3.84840459e-01 -7.30185390e-01 ...  0.00000000e+00\n",
      "    4.60725743e-04  0.00000000e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
      "    0.00000000e+00  2.22222233e+00]\n",
      "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
      "    1.15181436e-04  2.22222233e+00]\n",
      "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
      "    2.30362872e-04  2.22222233e+00]\n",
      "  [ 0.00000000e+00  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
      "    3.45544337e-04  2.22222233e+00]\n",
      "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
      "    4.60725743e-04  2.22222233e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  2.22222233e+00]\n",
      "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
      "    1.15181436e-04  2.22222233e+00]\n",
      "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
      "    2.30362872e-04  2.22222233e+00]\n",
      "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
      "    3.45544337e-04  2.22222233e+00]\n",
      "  [-8.40891719e-01  0.00000000e+00 -7.30185390e-01 ...  2.22222209e+00\n",
      "    4.60725743e-04  2.22222233e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
      "    0.00000000e+00  2.22222233e+00]\n",
      "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
      "    1.15181436e-04  0.00000000e+00]\n",
      "  [ 1.01033056e+00  6.48725748e-01  1.04046082e+00 ...  2.22222233e+00\n",
      "    2.30362872e-04  2.22222233e+00]\n",
      "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  0.00000000e+00\n",
      "    3.45544337e-04  2.22222233e+00]\n",
      "  [-8.40891719e-01  3.84840459e-01  0.00000000e+00 ...  2.22222209e+00\n",
      "    4.60725743e-04  2.22222233e+00]]\n",
      "\n",
      " [[ 0.00000000e+00  2.22222233e+00  0.00000000e+00 ...  2.22222233e+00\n",
      "    0.00000000e+00  2.22222233e+00]\n",
      "  [ 9.34967756e-01  1.71144700e+00  9.13173616e-01 ...  2.22222233e+00\n",
      "    1.15181436e-04  2.22222233e+00]\n",
      "  [ 1.01033056e+00  0.00000000e+00  1.04046082e+00 ...  2.22222233e+00\n",
      "    2.30362872e-04  2.22222233e+00]\n",
      "  [ 1.56800017e-01  1.11194458e-02  2.72317141e-01 ...  2.22222233e+00\n",
      "    3.45544337e-04  2.22222233e+00]\n",
      "  [-8.40891719e-01  3.84840459e-01 -7.30185390e-01 ...  2.22222209e+00\n",
      "    4.60725743e-04  2.22222233e+00]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "enc_vocab_size=20 #vocabulary size for the encoder\n",
    "input_seq_len=5 #max size of the i/p seq\n",
    "h=8 #number of self-attention heads\n",
    "d_k=64 #dimentionality of the linearly projected queris and keys\n",
    "d_v=64 #dimentionality of the linearly projected values\n",
    "d_ff=2048 #dimentionality of the inner fully connected layer\n",
    "d_model=512 #dimentionality of the model sub-layers' o/p\n",
    "n=6 #numer of layers in the encoder stack\n",
    "\n",
    "batch_size=64 #batch size form the the training process\n",
    "dropout_rate=0.1 #frequency of dropping the i/p units in the dropout layer\n",
    "input_seq=random.random((batch_size,input_seq_len))\n",
    "\n",
    "encoder=Encoder(enc_vocab_size,input_seq_len,h,d_k,d_v,d_model,d_ff,n,dropout_rate)\n",
    "print(encoder(input_seq,None,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319dc8f1-d62f-48d4-9dfe-4ef66658a1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
